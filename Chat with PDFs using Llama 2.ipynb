{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyOlUELPdmkq31kaslNJiqfA",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/oubbatimo/LLM-Chatbot/blob/main/Chat%20with%20PDFs%20using%20Llama%202.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EMSjxlpopOn4"
      },
      "outputs": [],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install langchain\n",
        "!pip install pypdf\n",
        "!pip install unstructured\n",
        "!pip install sentence_transformers\n",
        "!pip install pinecone-client\n",
        "!pip install llama-cpp-python\n",
        "!pip install huggingface_hub"
      ],
      "metadata": {
        "id": "jlnol3UZpli8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from langchain.document_loaders import PyPDFLoader, OnlinePDFLoader\n",
        "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
        "from langchain.embeddings import HuggingFaceEmbeddings\n",
        "from langchain.vectorstores import Pinecone\n",
        "from sentence_transformers import SentenceTransformer\n",
        "from langchain.chains.question_answering import load_qa_chain\n",
        "import pinecone\n",
        "import os"
      ],
      "metadata": {
        "id": "MU3tC9KRq_pV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "loader = PyPDFLoader(\"/content/AIDoc.pdf\")"
      ],
      "metadata": {
        "id": "O25KYrFwzjjf"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data=loader.load()"
      ],
      "metadata": {
        "id": "cEgaRHw3zwfV"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "data"
      ],
      "metadata": {
        "id": "ke3Wxi-A0Si8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text_splitter=RecursiveCharacterTextSplitter(chunk_size=500, chunk_overlap=0)"
      ],
      "metadata": {
        "id": "47L2kzQl0jbx"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docs=text_splitter.split_documents(data)"
      ],
      "metadata": {
        "id": "VDhe4GCq2Hd7"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "len(docs)\n"
      ],
      "metadata": {
        "id": "aUBxubwj2MRY",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "3cd740ef-b358-4986-d603-6c54399fb986"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "202"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[2]"
      ],
      "metadata": {
        "id": "vrVlJnov4jG5",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "8eb38072-1d05-4b02-a5d0-a32308aaec9a"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='ods. Finally, we look into future directions for Document AI research.\\n1 D OCUMENT AI\\nDocument AI, or Document Intelligence, is a booming research topic with increased industrial\\ndemand in recent years. It mainly refers to the process of automated understanding, classifying\\nand extracting information with rich typesetting formats from webpages, digital-born documents or\\nscanned documents through AI technology. Due to the diversity of layouts and formats, low-quality', metadata={'source': '/content/AIDoc.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "docs[4]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rKJ4e2z80NRq",
        "outputId": "5fa8a14a-ba2a-4ef4-c2f7-477a0345f7ee"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "Document(page_content='example, they not only contain the processing details and knowledge accumulation of a company’s\\ninternal and external affairs, but also a large number of industry-related entities and digital infor-\\nmation. Manually extracting information is time-consuming and labor-intensive with low accuracy\\nand low reusability. Document AI deeply combines artiﬁcial intelligence and human intelligence,\\nand has different types of applications in multiple industries such as ﬁnance, healthcare, insurance,', metadata={'source': '/content/AIDoc.pdf', 'page': 0})"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "os.environ[\"HUGGINGFACEHUB_API_TOKEN\"] = \"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\"\n",
        "PINECONE_API_KEY = os.environ.get('PINECONE_API_KEY', '19f79b62-157f-4def-903f-952152140404')\n",
        "PINECONE_API_ENV = os.environ.get('PINECONE_API_ENV', 'gcp-starter')"
      ],
      "metadata": {
        "id": "onWureAC6WIo"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "embeddings=HuggingFaceEmbeddings(model_name='sentence-transformers/all-MiniLM-L6-v2')"
      ],
      "metadata": {
        "id": "Y-4MnRAK7LWk"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "pinecone.init(\n",
        "    api_key=PINECONE_API_KEY,  # find at app.pinecone.io\n",
        "    environment=PINECONE_API_ENV  # next to api key in console\n",
        ")\n",
        "index_name = \"langchainpinecone\""
      ],
      "metadata": {
        "id": "Y9UBLKvQ75pa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "docsearch=Pinecone.from_texts([t.page_content for t in docs], embeddings, index_name=index_name)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 363
        },
        "id": "kctJ4N_S8q4a",
        "outputId": "37a701bc-3d15-42dd-eef3-db3b521582ac"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-28-9d9e640bc66a>\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mdocsearch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mPinecone\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfrom_texts\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mt\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpage_content\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mt\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdocs\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membeddings\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mindex_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py\u001b[0m in \u001b[0;36mfrom_texts\u001b[0;34m(cls, texts, embedding, metadatas, ids, batch_size, text_key, namespace, index_name, upsert_kwargs, pool_threads, embeddings_chunk_size, **kwargs)\u001b[0m\n\u001b[1;32m    419\u001b[0m                 )\n\u001b[1;32m    420\u001b[0m         \"\"\"\n\u001b[0;32m--> 421\u001b[0;31m         \u001b[0mpinecone_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_pinecone_index\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mindex_name\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpool_threads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    422\u001b[0m         \u001b[0mpinecone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcls\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mpinecone_index\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0membedding\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtext_key\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mnamespace\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    423\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.10/dist-packages/langchain_community/vectorstores/pinecone.py\u001b[0m in \u001b[0;36mget_pinecone_index\u001b[0;34m(cls, index_name, pool_threads)\u001b[0m\n\u001b[1;32m    371\u001b[0m             )\n\u001b[1;32m    372\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 373\u001b[0;31m             raise ValueError(\n\u001b[0m\u001b[1;32m    374\u001b[0m                 \u001b[0;34mf\"Index '{index_name}' not found in your Pinecone project. \"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    375\u001b[0m                 \u001b[0;34mf\"Did you mean one of the following indexes: {', '.join(indexes)}\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: Index 'langchainpinecone' not found in your Pinecone project. Did you mean one of the following indexes: bridgeai"
          ]
        }
      ]
    }
  ]
}